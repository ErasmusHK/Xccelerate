{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1661400789212,"user":{"displayName":"Satyajit Pattnaik","userId":"13090760809008372117"},"user_tz":-480},"id":"umLKy1txT1qy"},"outputs":[],"source":["import keras\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout\n","import numpy as np\n","import pandas as pd\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n","from sklearn.preprocessing import StandardScaler\n","import tensorflow as tf"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":399,"status":"ok","timestamp":1661400885556,"user":{"displayName":"Satyajit Pattnaik","userId":"13090760809008372117"},"user_tz":-480},"id":"O0OcyU1TT1q0"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Class</th>\n","      <th>age</th>\n","      <th>menopause</th>\n","      <th>tumor-size</th>\n","      <th>inv-nodes</th>\n","      <th>node-caps</th>\n","      <th>deg-malig</th>\n","      <th>breast</th>\n","      <th>breast-quad</th>\n","      <th>irradiat</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>no-recurrence-events</td>\n","      <td>30-39</td>\n","      <td>premeno</td>\n","      <td>30-34</td>\n","      <td>0-2</td>\n","      <td>no</td>\n","      <td>3</td>\n","      <td>left</td>\n","      <td>left_low</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>no-recurrence-events</td>\n","      <td>40-49</td>\n","      <td>premeno</td>\n","      <td>20-24</td>\n","      <td>0-2</td>\n","      <td>no</td>\n","      <td>2</td>\n","      <td>right</td>\n","      <td>right_up</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>no-recurrence-events</td>\n","      <td>40-49</td>\n","      <td>premeno</td>\n","      <td>20-24</td>\n","      <td>0-2</td>\n","      <td>no</td>\n","      <td>2</td>\n","      <td>left</td>\n","      <td>left_low</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>no-recurrence-events</td>\n","      <td>60-69</td>\n","      <td>ge40</td>\n","      <td>15-19</td>\n","      <td>0-2</td>\n","      <td>no</td>\n","      <td>2</td>\n","      <td>right</td>\n","      <td>left_up</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>no-recurrence-events</td>\n","      <td>40-49</td>\n","      <td>premeno</td>\n","      <td>0-4</td>\n","      <td>0-2</td>\n","      <td>no</td>\n","      <td>2</td>\n","      <td>right</td>\n","      <td>right_low</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>281</th>\n","      <td>recurrence-events</td>\n","      <td>30-39</td>\n","      <td>premeno</td>\n","      <td>30-34</td>\n","      <td>0-2</td>\n","      <td>no</td>\n","      <td>2</td>\n","      <td>left</td>\n","      <td>left_up</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>282</th>\n","      <td>recurrence-events</td>\n","      <td>30-39</td>\n","      <td>premeno</td>\n","      <td>20-24</td>\n","      <td>0-2</td>\n","      <td>no</td>\n","      <td>3</td>\n","      <td>left</td>\n","      <td>left_up</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>283</th>\n","      <td>recurrence-events</td>\n","      <td>60-69</td>\n","      <td>ge40</td>\n","      <td>20-24</td>\n","      <td>0-2</td>\n","      <td>no</td>\n","      <td>1</td>\n","      <td>right</td>\n","      <td>left_up</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>284</th>\n","      <td>recurrence-events</td>\n","      <td>40-49</td>\n","      <td>ge40</td>\n","      <td>30-34</td>\n","      <td>3-5</td>\n","      <td>no</td>\n","      <td>3</td>\n","      <td>left</td>\n","      <td>left_low</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>285</th>\n","      <td>recurrence-events</td>\n","      <td>50-59</td>\n","      <td>ge40</td>\n","      <td>30-34</td>\n","      <td>3-5</td>\n","      <td>no</td>\n","      <td>3</td>\n","      <td>left</td>\n","      <td>left_low</td>\n","      <td>no</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>286 rows Ã— 10 columns</p>\n","</div>"],"text/plain":["                    Class    age menopause tumor-size inv-nodes node-caps  \\\n","0    no-recurrence-events  30-39   premeno      30-34       0-2        no   \n","1    no-recurrence-events  40-49   premeno      20-24       0-2        no   \n","2    no-recurrence-events  40-49   premeno      20-24       0-2        no   \n","3    no-recurrence-events  60-69      ge40      15-19       0-2        no   \n","4    no-recurrence-events  40-49   premeno        0-4       0-2        no   \n","..                    ...    ...       ...        ...       ...       ...   \n","281     recurrence-events  30-39   premeno      30-34       0-2        no   \n","282     recurrence-events  30-39   premeno      20-24       0-2        no   \n","283     recurrence-events  60-69      ge40      20-24       0-2        no   \n","284     recurrence-events  40-49      ge40      30-34       3-5        no   \n","285     recurrence-events  50-59      ge40      30-34       3-5        no   \n","\n","     deg-malig breast breast-quad irradiat  \n","0            3   left    left_low       no  \n","1            2  right    right_up       no  \n","2            2   left    left_low       no  \n","3            2  right     left_up       no  \n","4            2  right   right_low       no  \n","..         ...    ...         ...      ...  \n","281          2   left     left_up       no  \n","282          3   left     left_up      yes  \n","283          1  right     left_up       no  \n","284          3   left    left_low       no  \n","285          3   left    left_low       no  \n","\n","[286 rows x 10 columns]"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv('.\\\\data\\\\breast-cancer.data', names=[\"Class\", \"age\", \"menopause\", \"tumor-size\", \"inv-nodes\", \"node-caps\", \"deg-malig\", \"breast\", \"breast-quad\", \"irradiat\"])\n","df"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Question 1 )"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# we want to encode the age column as follows: \n","# if age is 20-29, encode as 1 \n","# if age is 30-39, encode as 2,... \n","# so on if age is 70-79, encode as 6 \n","# return a new Series called cancer['newAge']\n","df[\"newAge\"] = df[\"age\"].replace({k:i+1 for i,k in enumerate(sorted(set(df[\"age\"])))})\n","\n","# After that, we will also encode the tumor size and inv-nodes using our own encoding functions.\n","# Then, we will one hot encode the other columns(i.e. tumor-size and inv-nodes).\n","df_q1 = pd.get_dummies(df.iloc[:,2:], drop_first=True)\n","df[\"Class\"] = LabelEncoder().fit_transform(df[\"Class\"])"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Question 2 )"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# Now, split the data into 70%/ 30% training and testing set, set random_state = 101\n","x = df_q1\n","y = df[\"Class\"]\n","x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state = 101)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Question 3 )"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# Now, Scale X_train and X_test using Standard Scaler\n","ss = StandardScaler()\n","x_train = ss.fit_transform(x_train)\n","x_test = ss.transform(x_test)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Question 4 )"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","4/4 [==============================] - 1s 4ms/step - loss: 0.6927 - accuracy: 0.7050\n","Epoch 2/20\n","4/4 [==============================] - 0s 3ms/step - loss: 0.6914 - accuracy: 0.7250\n","Epoch 3/20\n","4/4 [==============================] - 0s 3ms/step - loss: 0.6898 - accuracy: 0.7250\n","Epoch 4/20\n","4/4 [==============================] - 0s 3ms/step - loss: 0.6879 - accuracy: 0.7250\n","Epoch 5/20\n","4/4 [==============================] - 0s 3ms/step - loss: 0.6852 - accuracy: 0.7250\n","Epoch 6/20\n","4/4 [==============================] - 0s 4ms/step - loss: 0.6823 - accuracy: 0.7250\n","Epoch 7/20\n","4/4 [==============================] - 0s 3ms/step - loss: 0.6766 - accuracy: 0.7250\n","Epoch 8/20\n","4/4 [==============================] - 0s 4ms/step - loss: 0.6684 - accuracy: 0.7250\n","Epoch 9/20\n","4/4 [==============================] - 0s 3ms/step - loss: 0.6562 - accuracy: 0.7250\n","Epoch 10/20\n","4/4 [==============================] - 0s 3ms/step - loss: 0.6395 - accuracy: 0.7250\n","Epoch 11/20\n","4/4 [==============================] - 0s 3ms/step - loss: 0.6128 - accuracy: 0.7250\n","Epoch 12/20\n","4/4 [==============================] - 0s 3ms/step - loss: 0.5788 - accuracy: 0.7250\n","Epoch 13/20\n","4/4 [==============================] - 0s 3ms/step - loss: 0.5433 - accuracy: 0.7250\n","Epoch 14/20\n","4/4 [==============================] - 0s 3ms/step - loss: 0.5107 - accuracy: 0.7250\n","Epoch 15/20\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4998 - accuracy: 0.7250\n","Epoch 16/20\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4990 - accuracy: 0.7250\n","Epoch 17/20\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4935 - accuracy: 0.7250\n","Epoch 18/20\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4830 - accuracy: 0.7250\n","Epoch 19/20\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4761 - accuracy: 0.7250\n","Epoch 20/20\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4705 - accuracy: 0.7250\n","3/3 [==============================] - 0s 2ms/step\n","loss : 0.75582665\n","accuracy : 0.6511627906976745\n"]}],"source":["# Make the neural network as follows\n","# 1st Hidden layer: use Dense layer, with 32 units, uniform kernel initializer, relu activation,you have to figure out the input_dim\n","# 2nd Hidden layer: use Dense layer, with 32 units, uniform kernel initializer, relu activation\n","# 3rd Hidden layer: use Dense layer, with 32 units, uniform kernel initializer, relu activation\n","# 4th Hidden layer: use Dense layer, with 32 units, uniform kernel initializer, relu activation\n","# Output layer: you have to figure out the number of output units and the activation function you use, use uniform kernel initializer.\n","classifier_q4 = Sequential()\n","classifier_q4.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu', input_dim = 29))\n","classifier_q4.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu'))\n","classifier_q4.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu'))\n","classifier_q4.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu'))\n","classifier_q4.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n","\n","# After that, compile the ANN with adam optimizer, use accuracy as metrics and figure out the appropriate loss function.\n","# After that, fit the model with 50 batch_size, and 20 epochs\n","classifier_q4.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n","classifier_q4.fit(x_train, y_train, batch_size = 50, epochs = 20)\n","\n","# Then, return the loss and accuracy\n","y_pred_q4 = classifier_q4.predict(x_test)\n","print(\"loss :\", tf.losses.BinaryCrossentropy()(y_test, y_pred_q4).numpy())\n","print(\"accuracy :\", accuracy_score(y_test, (y_pred_q4 > 0.5)))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Question 5 )"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","4/4 [==============================] - 1s 3ms/step - loss: 0.6926 - accuracy: 0.6850\n","Epoch 2/20\n","4/4 [==============================] - 0s 3ms/step - loss: 0.6913 - accuracy: 0.7250\n","Epoch 3/20\n","4/4 [==============================] - 0s 3ms/step - loss: 0.6899 - accuracy: 0.7250\n","Epoch 4/20\n","4/4 [==============================] - 0s 3ms/step - loss: 0.6882 - accuracy: 0.7250\n","Epoch 5/20\n","4/4 [==============================] - 0s 3ms/step - loss: 0.6863 - accuracy: 0.7250\n","Epoch 6/20\n","4/4 [==============================] - 0s 3ms/step - loss: 0.6829 - accuracy: 0.7250\n","Epoch 7/20\n","4/4 [==============================] - 0s 3ms/step - loss: 0.6787 - accuracy: 0.7250\n","Epoch 8/20\n","4/4 [==============================] - 0s 3ms/step - loss: 0.6726 - accuracy: 0.7250\n","Epoch 9/20\n","4/4 [==============================] - 0s 2ms/step - loss: 0.6623 - accuracy: 0.7250\n","Epoch 10/20\n","4/4 [==============================] - 0s 3ms/step - loss: 0.6482 - accuracy: 0.7250\n","Epoch 11/20\n","4/4 [==============================] - 0s 3ms/step - loss: 0.6218 - accuracy: 0.7250\n","Epoch 12/20\n","4/4 [==============================] - 0s 3ms/step - loss: 0.5886 - accuracy: 0.7250\n","Epoch 13/20\n","4/4 [==============================] - 0s 3ms/step - loss: 0.5530 - accuracy: 0.7250\n","Epoch 14/20\n","4/4 [==============================] - 0s 3ms/step - loss: 0.5258 - accuracy: 0.7250\n","Epoch 15/20\n","4/4 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7250\n","Epoch 16/20\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4975 - accuracy: 0.7250\n","Epoch 17/20\n","4/4 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.7250\n","Epoch 18/20\n","4/4 [==============================] - 0s 3ms/step - loss: 0.5017 - accuracy: 0.7250\n","Epoch 19/20\n","4/4 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.7250\n","Epoch 20/20\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4808 - accuracy: 0.7250\n","3/3 [==============================] - 0s 1ms/step\n","loss : 0.76149774\n","accuracy : 0.6511627906976745\n"]}],"source":["# Now, make another neural network with some Dropout layer to avoid overfitting\n","# 1st layer: use Dense layer, with 32 units, uniform kernel initializer, relu activation, you have to figure out the input_dim\n","# 2nd layer: use Dense layer, with 32 units, uniform kernel initializer, relu activation\n","# 3rd layer: use Dense layer, with 32 units, uniform kernel initializer, relu activation\n","# 4th layer: use Dense layer, with 32 units, uniform kernel initializer, relu activation\n","# 5th layer: Dropout with 0.3 rate\n","# 6th layer: you have to figure out the number of output units and the activation function you use, use uniform kernel initializer.\n","classifier_q5 = Sequential()\n","classifier_q5.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu', input_dim = 29))\n","classifier_q5.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu'))\n","classifier_q5.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu'))\n","classifier_q5.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu'))\n","classifier_q5.add(Dropout(0.3))\n","classifier_q5.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n","\n","# After that, compile the ANN with adam optimizer, use accuracy as metrics and figure out the appropriate loss function.\n","# After that, fit the model with 50 batch_size, and 20 epochs\n","classifier_q5.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n","classifier_q5.fit(x_train, y_train, batch_size = 50, epochs = 20)\n","\n","# Then return the loss and accuracy.\n","y_pred_q5 = classifier_q5.predict(x_test)\n","print(\"loss :\", tf.losses.BinaryCrossentropy()(y_test, y_pred_q5).numpy())\n","print(\"accuracy :\", accuracy_score(y_test, (y_pred_q5 > 0.5)))"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"CML+ANN_Churn_Use_Case (2).ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"d3dc24cc7e02586248f8d00edbc6455c95af5b22abe18b79a1c967fbdeaf1c4e"}}},"nbformat":4,"nbformat_minor":0}
